{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweeter_ner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhqbFO-3mUyJ",
        "colab_type": "text"
      },
      "source": [
        " \n",
        " Tweet Sentiment NER approach\n",
        " \n",
        " Inspired from -\n",
        "\n",
        " https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/\n",
        "\n",
        "https://www.kaggle.com/gskdhiman/bert-baseline-starter-kernel-ner-approach\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1qpP0EwmP2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I84q7DM8-I6I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3882f36-ef34-4e20-d0f6-e6e24153aacd"
      },
      "source": [
        "link='https://drive.google.com/open?id=1YK66P0Oi-oF-untCgXFtIO3062DGlQHY'\n",
        "fluff, id = link.split('=')\n",
        "print (id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1YK66P0Oi-oF-untCgXFtIO3062DGlQHY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYCAUIXZAjyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install required packages\n",
        "! pip install transformers==2.8.0\n",
        "import os\n",
        "import gc\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertTokenizer,BertConfig,TFBertModel\n",
        "from tqdm import tqdm\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmztnWniDrlL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b6153b4c-e503-416b-8889-d564a4984d4f"
      },
      "source": [
        "# Load vocab file\n",
        "! wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-16 16:10:39--  https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.8.126\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.8.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 231508 (226K) [text/plain]\n",
            "Saving to: ‘bert-base-uncased-vocab.txt’\n",
            "\n",
            "bert-base-uncased-v 100%[===================>] 226.08K   813KB/s    in 0.3s    \n",
            "\n",
            "2020-06-16 16:10:40 (813 KB/s) - ‘bert-base-uncased-vocab.txt’ saved [231508/231508]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D06lyVajiK-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tokenizers\n",
        "tokenizer=tokenizers.BertWordPieceTokenizer(\"bert-base-uncased-vocab.txt\",lowercase=True)\n",
        "#tokenizer=tokenizer.add_special_tokens([ \"[SEP]\", \"[UNK]\", \"[T1]\", \"[T2]\" ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMTSkV-B-I9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fa2a282a-d3eb-4b28-9d0a-7326f7c518d4"
      },
      "source": [
        "# Get the GPU device name.set_device()\n",
        "device_name = tf.test.gpu_device_name()\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    #device = torch.cuda.set_device(0)\n",
        "    device = torch.device('cuda:0')\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTpYb616-JAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### data preprocessing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "\n",
        "downloaded.GetContentFile('train.csv')  \n",
        "df = pd.read_csv('train.csv')\n",
        "df=df.drop([i for i in range(len(df['text'])) if  df['text'][i] in ['nan', np.nan]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5JLQWvgbp2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_data(tweet, selected_text, tokenizer):\n",
        "  \"\"\" This function will create target list ,selected text as 1 and otherwise 0\n",
        "  \"\"\"\n",
        "    len_st = len(selected_text)\n",
        "    idx0 = None\n",
        "    idx1 = None\n",
        "\n",
        "    for ind in (i for i, e in enumerate(tweet) if e == selected_text[0]):\n",
        "        if tweet[ind: ind+len_st] == selected_text:\n",
        "            idx0 = ind\n",
        "            idx1 = ind + len_st\n",
        "            break\n",
        "\n",
        "    char_targets = [0] * len(tweet)\n",
        "    if idx0 != None and idx1 != None:\n",
        "        for ct in range(idx0, idx1):\n",
        "            char_targets[ct] = 1\n",
        "            \n",
        "    tok_tweet = tokenizer.encode(tweet)\n",
        "    input_ids_orig = tok_tweet.ids\n",
        "    tweet_offsets = tok_tweet.offsets\n",
        "\n",
        "    target_idx = []\n",
        "    for j, (offset1, offset2) in enumerate(tweet_offsets):\n",
        "        if sum(char_targets[offset1: offset2]) > 0:\n",
        "            target_idx.append(j)\n",
        "            \n",
        "    targets = [0] * len(input_ids_orig)\n",
        "    for idx in target_idx:\n",
        "        targets[idx] = 1\n",
        "    return targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PahIeumxuFsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['targets'] = df.apply(lambda row: process_data(str(row['text']), \n",
        "                                                                    str(row['selected_text']),\n",
        "                                                                    tokenizer),\n",
        "                                                                    axis=1)\n",
        "max_len=128\n",
        "df['targets'] = df['targets'].apply(lambda x :x + [0] * (max_len-len(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY_2PuVebqA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "#from transformers import BertTokenizer, BertConfig\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "tokenizer_brt = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lX14Zpnoy1B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8827caf7-07c0-4a21-9801-09b899b6c6b7"
      },
      "source": [
        "%%time\n",
        "# Create input token ids, attention mask and target tags and keep all of them in dictionary\n",
        "text_tag_list=[]\n",
        "for id in df['textID']:\n",
        "  tweet=df[df['textID']==id]['text'].values[0]\n",
        "  tag=df['targets'][df['textID']==id].values[0]\n",
        "  tweet_token=tokenizer_brt.encode_plus(tweet,max_length=128,pad_to_max_length=True,return_attention_mask = True)\n",
        "  text_tag_list.append({'id':id,'tweet':tweet,'tweet_token':tweet_token['input_ids'],'attention_mask':tweet_token['attention_mask'],'tag':tag})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 2s, sys: 123 ms, total: 2min 2s\n",
            "Wall time: 2min 2s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38j3Tf4NnfUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Text train split and converting to tensor\n",
        "\n",
        "train_text_tag,val_text_tag=train_test_split(text_tag_list,random_state=2018,test_size=.1)\n",
        "tr_inputs=torch.tensor([train_text_tag[i]['tweet_token'] for i in range(len(train_text_tag))])\n",
        "val_inputs=torch.tensor([val_text_tag[i]['tweet_token'] for i in range(len(val_text_tag))])\n",
        "tr_tags=torch.tensor([train_text_tag[i]['tag'] for i in range(len(train_text_tag))])\n",
        "val_tags=torch.tensor([val_text_tag[i]['tag'] for i in range(len(val_text_tag))])\n",
        "tr_masks=torch.tensor([train_text_tag[i]['attention_mask'] for i in range(len(train_text_tag))])\n",
        "val_masks=torch.tensor([val_text_tag[i]['attention_mask'] for i in range(len(val_text_tag))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4C9v0MUEcco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pytorch data loader to load train and validation sheet\n",
        "bs = 32\n",
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92tV3UvVDMxc",
        "colab_type": "text"
      },
      "source": [
        "Build Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZOxb8gYO9xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForTokenClassification, AdamW"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMO3uICrPY7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained(\n",
        "    \"bert-base-cased\",\n",
        "    num_labels=2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        ")\n",
        "##model.resize_token_embeddings(len(tokenizer_brt))\n",
        "#model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc7jIhKt9X_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26a11beb-bd7e-4d9c-c77a-2082e3283652"
      },
      "source": [
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8P0Nglq6gcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters())\n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1Yp73NH6ggH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 1\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmZmlpTyDUI7",
        "colab_type": "text"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzVSZx_Xed3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97b377fd-fdef-41b3-dfbe-1febc09c153c"
      },
      "source": [
        "%%time\n",
        "## Store the average loss after each epoch so we can plot them.\n",
        "loss_values, validation_loss_values = [], []\n",
        "\n",
        "for i in range(0,epochs):\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        model.zero_grad()\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                        attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        print(loss,step)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in valid_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have not provided labels.\n",
        "            outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask, labels=b_labels)\n",
        "        # Move logits and labels to CPU\n",
        "        logits = outputs[1].detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        eval_loss += outputs[0].mean().item()\n",
        "        print(\"eval loss  :\"+str(eval_loss))\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        true_labels.extend(label_ids)\n",
        "\n",
        "    eval_loss = eval_loss / len(valid_dataloader)\n",
        "    validation_loss_values.append(eval_loss)\n",
        "    #print(\"Validation loss: {}\".format(eval_loss))\n",
        "    #pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "    #                             for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
        "    #valid_tags = [tag_values[l_i] for l in true_labels\n",
        "    #                              for l_i in l if tag_values[l_i] != \"PAD\"]\n",
        "    #print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n",
        "    #print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n",
        "    print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.7593, device='cuda:0', grad_fn=<NllLossBackward>) 0\n",
            "tensor(0.6898, device='cuda:0', grad_fn=<NllLossBackward>) 1\n",
            "tensor(0.7739, device='cuda:0', grad_fn=<NllLossBackward>) 2\n",
            "tensor(0.6959, device='cuda:0', grad_fn=<NllLossBackward>) 3\n",
            "tensor(0.7218, device='cuda:0', grad_fn=<NllLossBackward>) 4\n",
            "tensor(0.6577, device='cuda:0', grad_fn=<NllLossBackward>) 5\n",
            "tensor(0.6510, device='cuda:0', grad_fn=<NllLossBackward>) 6\n",
            "tensor(0.7000, device='cuda:0', grad_fn=<NllLossBackward>) 7\n",
            "tensor(0.8127, device='cuda:0', grad_fn=<NllLossBackward>) 8\n",
            "tensor(0.6430, device='cuda:0', grad_fn=<NllLossBackward>) 9\n",
            "tensor(0.6437, device='cuda:0', grad_fn=<NllLossBackward>) 10\n",
            "tensor(0.6660, device='cuda:0', grad_fn=<NllLossBackward>) 11\n",
            "tensor(0.6599, device='cuda:0', grad_fn=<NllLossBackward>) 12\n",
            "tensor(0.6222, device='cuda:0', grad_fn=<NllLossBackward>) 13\n",
            "tensor(0.6980, device='cuda:0', grad_fn=<NllLossBackward>) 14\n",
            "tensor(0.6022, device='cuda:0', grad_fn=<NllLossBackward>) 15\n",
            "tensor(0.6323, device='cuda:0', grad_fn=<NllLossBackward>) 16\n",
            "tensor(0.6426, device='cuda:0', grad_fn=<NllLossBackward>) 17\n",
            "tensor(0.6813, device='cuda:0', grad_fn=<NllLossBackward>) 18\n",
            "tensor(0.6285, device='cuda:0', grad_fn=<NllLossBackward>) 19\n",
            "tensor(0.6268, device='cuda:0', grad_fn=<NllLossBackward>) 20\n",
            "tensor(0.6338, device='cuda:0', grad_fn=<NllLossBackward>) 21\n",
            "tensor(0.6176, device='cuda:0', grad_fn=<NllLossBackward>) 22\n",
            "tensor(0.6604, device='cuda:0', grad_fn=<NllLossBackward>) 23\n",
            "tensor(0.6275, device='cuda:0', grad_fn=<NllLossBackward>) 24\n",
            "tensor(0.5936, device='cuda:0', grad_fn=<NllLossBackward>) 25\n",
            "tensor(0.6489, device='cuda:0', grad_fn=<NllLossBackward>) 26\n",
            "tensor(0.6442, device='cuda:0', grad_fn=<NllLossBackward>) 27\n",
            "tensor(0.6240, device='cuda:0', grad_fn=<NllLossBackward>) 28\n",
            "tensor(0.5847, device='cuda:0', grad_fn=<NllLossBackward>) 29\n",
            "tensor(0.6283, device='cuda:0', grad_fn=<NllLossBackward>) 30\n",
            "tensor(0.6278, device='cuda:0', grad_fn=<NllLossBackward>) 31\n",
            "tensor(0.6299, device='cuda:0', grad_fn=<NllLossBackward>) 32\n",
            "tensor(0.6178, device='cuda:0', grad_fn=<NllLossBackward>) 33\n",
            "tensor(0.6094, device='cuda:0', grad_fn=<NllLossBackward>) 34\n",
            "tensor(0.6301, device='cuda:0', grad_fn=<NllLossBackward>) 35\n",
            "tensor(0.6034, device='cuda:0', grad_fn=<NllLossBackward>) 36\n",
            "tensor(0.6200, device='cuda:0', grad_fn=<NllLossBackward>) 37\n",
            "tensor(0.6690, device='cuda:0', grad_fn=<NllLossBackward>) 38\n",
            "tensor(0.6405, device='cuda:0', grad_fn=<NllLossBackward>) 39\n",
            "tensor(0.6400, device='cuda:0', grad_fn=<NllLossBackward>) 40\n",
            "tensor(0.6187, device='cuda:0', grad_fn=<NllLossBackward>) 41\n",
            "tensor(0.6570, device='cuda:0', grad_fn=<NllLossBackward>) 42\n",
            "tensor(0.6616, device='cuda:0', grad_fn=<NllLossBackward>) 43\n",
            "tensor(0.6165, device='cuda:0', grad_fn=<NllLossBackward>) 44\n",
            "tensor(0.6053, device='cuda:0', grad_fn=<NllLossBackward>) 45\n",
            "tensor(0.6253, device='cuda:0', grad_fn=<NllLossBackward>) 46\n",
            "tensor(0.6510, device='cuda:0', grad_fn=<NllLossBackward>) 47\n",
            "tensor(0.6446, device='cuda:0', grad_fn=<NllLossBackward>) 48\n",
            "tensor(0.6599, device='cuda:0', grad_fn=<NllLossBackward>) 49\n",
            "tensor(0.6347, device='cuda:0', grad_fn=<NllLossBackward>) 50\n",
            "tensor(0.6445, device='cuda:0', grad_fn=<NllLossBackward>) 51\n",
            "tensor(0.6350, device='cuda:0', grad_fn=<NllLossBackward>) 52\n",
            "tensor(0.6241, device='cuda:0', grad_fn=<NllLossBackward>) 53\n",
            "tensor(0.6229, device='cuda:0', grad_fn=<NllLossBackward>) 54\n",
            "tensor(0.6246, device='cuda:0', grad_fn=<NllLossBackward>) 55\n",
            "tensor(0.7050, device='cuda:0', grad_fn=<NllLossBackward>) 56\n",
            "tensor(0.6532, device='cuda:0', grad_fn=<NllLossBackward>) 57\n",
            "tensor(0.6181, device='cuda:0', grad_fn=<NllLossBackward>) 58\n",
            "tensor(0.6098, device='cuda:0', grad_fn=<NllLossBackward>) 59\n",
            "tensor(0.6418, device='cuda:0', grad_fn=<NllLossBackward>) 60\n",
            "tensor(0.6021, device='cuda:0', grad_fn=<NllLossBackward>) 61\n",
            "tensor(0.6290, device='cuda:0', grad_fn=<NllLossBackward>) 62\n",
            "tensor(0.5982, device='cuda:0', grad_fn=<NllLossBackward>) 63\n",
            "tensor(0.6543, device='cuda:0', grad_fn=<NllLossBackward>) 64\n",
            "tensor(0.5897, device='cuda:0', grad_fn=<NllLossBackward>) 65\n",
            "tensor(0.6315, device='cuda:0', grad_fn=<NllLossBackward>) 66\n",
            "tensor(0.5629, device='cuda:0', grad_fn=<NllLossBackward>) 67\n",
            "tensor(0.6178, device='cuda:0', grad_fn=<NllLossBackward>) 68\n",
            "tensor(0.6425, device='cuda:0', grad_fn=<NllLossBackward>) 69\n",
            "tensor(0.6129, device='cuda:0', grad_fn=<NllLossBackward>) 70\n",
            "tensor(0.6997, device='cuda:0', grad_fn=<NllLossBackward>) 71\n",
            "tensor(0.6612, device='cuda:0', grad_fn=<NllLossBackward>) 72\n",
            "tensor(0.6010, device='cuda:0', grad_fn=<NllLossBackward>) 73\n",
            "tensor(0.6789, device='cuda:0', grad_fn=<NllLossBackward>) 74\n",
            "tensor(0.6188, device='cuda:0', grad_fn=<NllLossBackward>) 75\n",
            "tensor(0.6442, device='cuda:0', grad_fn=<NllLossBackward>) 76\n",
            "tensor(0.6307, device='cuda:0', grad_fn=<NllLossBackward>) 77\n",
            "tensor(0.6382, device='cuda:0', grad_fn=<NllLossBackward>) 78\n",
            "tensor(0.6188, device='cuda:0', grad_fn=<NllLossBackward>) 79\n",
            "tensor(0.6399, device='cuda:0', grad_fn=<NllLossBackward>) 80\n",
            "tensor(0.6337, device='cuda:0', grad_fn=<NllLossBackward>) 81\n",
            "tensor(0.5983, device='cuda:0', grad_fn=<NllLossBackward>) 82\n",
            "tensor(0.6264, device='cuda:0', grad_fn=<NllLossBackward>) 83\n",
            "tensor(0.6160, device='cuda:0', grad_fn=<NllLossBackward>) 84\n",
            "tensor(0.6082, device='cuda:0', grad_fn=<NllLossBackward>) 85\n",
            "tensor(0.6339, device='cuda:0', grad_fn=<NllLossBackward>) 86\n",
            "tensor(0.5988, device='cuda:0', grad_fn=<NllLossBackward>) 87\n",
            "tensor(0.6049, device='cuda:0', grad_fn=<NllLossBackward>) 88\n",
            "tensor(0.6337, device='cuda:0', grad_fn=<NllLossBackward>) 89\n",
            "tensor(0.5964, device='cuda:0', grad_fn=<NllLossBackward>) 90\n",
            "tensor(0.6024, device='cuda:0', grad_fn=<NllLossBackward>) 91\n",
            "tensor(0.6256, device='cuda:0', grad_fn=<NllLossBackward>) 92\n",
            "tensor(0.6229, device='cuda:0', grad_fn=<NllLossBackward>) 93\n",
            "tensor(0.6176, device='cuda:0', grad_fn=<NllLossBackward>) 94\n",
            "tensor(0.5954, device='cuda:0', grad_fn=<NllLossBackward>) 95\n",
            "tensor(0.6011, device='cuda:0', grad_fn=<NllLossBackward>) 96\n",
            "tensor(0.5946, device='cuda:0', grad_fn=<NllLossBackward>) 97\n",
            "tensor(0.5809, device='cuda:0', grad_fn=<NllLossBackward>) 98\n",
            "tensor(0.6086, device='cuda:0', grad_fn=<NllLossBackward>) 99\n",
            "tensor(0.6238, device='cuda:0', grad_fn=<NllLossBackward>) 100\n",
            "tensor(0.6407, device='cuda:0', grad_fn=<NllLossBackward>) 101\n",
            "tensor(0.5635, device='cuda:0', grad_fn=<NllLossBackward>) 102\n",
            "tensor(0.6331, device='cuda:0', grad_fn=<NllLossBackward>) 103\n",
            "tensor(0.6016, device='cuda:0', grad_fn=<NllLossBackward>) 104\n",
            "tensor(0.6536, device='cuda:0', grad_fn=<NllLossBackward>) 105\n",
            "tensor(0.6239, device='cuda:0', grad_fn=<NllLossBackward>) 106\n",
            "tensor(0.6196, device='cuda:0', grad_fn=<NllLossBackward>) 107\n",
            "tensor(0.6400, device='cuda:0', grad_fn=<NllLossBackward>) 108\n",
            "tensor(0.6049, device='cuda:0', grad_fn=<NllLossBackward>) 109\n",
            "tensor(0.6209, device='cuda:0', grad_fn=<NllLossBackward>) 110\n",
            "tensor(0.6437, device='cuda:0', grad_fn=<NllLossBackward>) 111\n",
            "tensor(0.6403, device='cuda:0', grad_fn=<NllLossBackward>) 112\n",
            "tensor(0.6040, device='cuda:0', grad_fn=<NllLossBackward>) 113\n",
            "tensor(0.6309, device='cuda:0', grad_fn=<NllLossBackward>) 114\n",
            "tensor(0.6082, device='cuda:0', grad_fn=<NllLossBackward>) 115\n",
            "tensor(0.6157, device='cuda:0', grad_fn=<NllLossBackward>) 116\n",
            "tensor(0.5841, device='cuda:0', grad_fn=<NllLossBackward>) 117\n",
            "tensor(0.6113, device='cuda:0', grad_fn=<NllLossBackward>) 118\n",
            "tensor(0.6145, device='cuda:0', grad_fn=<NllLossBackward>) 119\n",
            "tensor(0.6126, device='cuda:0', grad_fn=<NllLossBackward>) 120\n",
            "tensor(0.6254, device='cuda:0', grad_fn=<NllLossBackward>) 121\n",
            "tensor(0.6118, device='cuda:0', grad_fn=<NllLossBackward>) 122\n",
            "tensor(0.6248, device='cuda:0', grad_fn=<NllLossBackward>) 123\n",
            "tensor(0.5866, device='cuda:0', grad_fn=<NllLossBackward>) 124\n",
            "tensor(0.6199, device='cuda:0', grad_fn=<NllLossBackward>) 125\n",
            "tensor(0.6196, device='cuda:0', grad_fn=<NllLossBackward>) 126\n",
            "tensor(0.5811, device='cuda:0', grad_fn=<NllLossBackward>) 127\n",
            "tensor(0.6169, device='cuda:0', grad_fn=<NllLossBackward>) 128\n",
            "tensor(0.5837, device='cuda:0', grad_fn=<NllLossBackward>) 129\n",
            "tensor(0.5992, device='cuda:0', grad_fn=<NllLossBackward>) 130\n",
            "tensor(0.6020, device='cuda:0', grad_fn=<NllLossBackward>) 131\n",
            "tensor(0.5839, device='cuda:0', grad_fn=<NllLossBackward>) 132\n",
            "tensor(0.5625, device='cuda:0', grad_fn=<NllLossBackward>) 133\n",
            "tensor(0.6845, device='cuda:0', grad_fn=<NllLossBackward>) 134\n",
            "tensor(0.6350, device='cuda:0', grad_fn=<NllLossBackward>) 135\n",
            "tensor(0.6013, device='cuda:0', grad_fn=<NllLossBackward>) 136\n",
            "tensor(0.5909, device='cuda:0', grad_fn=<NllLossBackward>) 137\n",
            "tensor(0.5825, device='cuda:0', grad_fn=<NllLossBackward>) 138\n",
            "tensor(0.6483, device='cuda:0', grad_fn=<NllLossBackward>) 139\n",
            "tensor(0.6151, device='cuda:0', grad_fn=<NllLossBackward>) 140\n",
            "tensor(0.6270, device='cuda:0', grad_fn=<NllLossBackward>) 141\n",
            "tensor(0.6138, device='cuda:0', grad_fn=<NllLossBackward>) 142\n",
            "tensor(0.6256, device='cuda:0', grad_fn=<NllLossBackward>) 143\n",
            "tensor(0.6242, device='cuda:0', grad_fn=<NllLossBackward>) 144\n",
            "tensor(0.6094, device='cuda:0', grad_fn=<NllLossBackward>) 145\n",
            "tensor(0.6057, device='cuda:0', grad_fn=<NllLossBackward>) 146\n",
            "tensor(0.5700, device='cuda:0', grad_fn=<NllLossBackward>) 147\n",
            "tensor(0.6419, device='cuda:0', grad_fn=<NllLossBackward>) 148\n",
            "tensor(0.6401, device='cuda:0', grad_fn=<NllLossBackward>) 149\n",
            "tensor(0.6118, device='cuda:0', grad_fn=<NllLossBackward>) 150\n",
            "tensor(0.6193, device='cuda:0', grad_fn=<NllLossBackward>) 151\n",
            "tensor(0.5912, device='cuda:0', grad_fn=<NllLossBackward>) 152\n",
            "tensor(0.6274, device='cuda:0', grad_fn=<NllLossBackward>) 153\n",
            "tensor(0.6218, device='cuda:0', grad_fn=<NllLossBackward>) 154\n",
            "tensor(0.6349, device='cuda:0', grad_fn=<NllLossBackward>) 155\n",
            "tensor(0.6251, device='cuda:0', grad_fn=<NllLossBackward>) 156\n",
            "tensor(0.6156, device='cuda:0', grad_fn=<NllLossBackward>) 157\n",
            "tensor(0.6593, device='cuda:0', grad_fn=<NllLossBackward>) 158\n",
            "tensor(0.6035, device='cuda:0', grad_fn=<NllLossBackward>) 159\n",
            "tensor(0.6262, device='cuda:0', grad_fn=<NllLossBackward>) 160\n",
            "tensor(0.6130, device='cuda:0', grad_fn=<NllLossBackward>) 161\n",
            "tensor(0.5890, device='cuda:0', grad_fn=<NllLossBackward>) 162\n",
            "tensor(0.6247, device='cuda:0', grad_fn=<NllLossBackward>) 163\n",
            "tensor(0.5831, device='cuda:0', grad_fn=<NllLossBackward>) 164\n",
            "tensor(0.6037, device='cuda:0', grad_fn=<NllLossBackward>) 165\n",
            "tensor(0.6219, device='cuda:0', grad_fn=<NllLossBackward>) 166\n",
            "tensor(0.6041, device='cuda:0', grad_fn=<NllLossBackward>) 167\n",
            "tensor(0.6048, device='cuda:0', grad_fn=<NllLossBackward>) 168\n",
            "tensor(0.6294, device='cuda:0', grad_fn=<NllLossBackward>) 169\n",
            "tensor(0.6409, device='cuda:0', grad_fn=<NllLossBackward>) 170\n",
            "tensor(0.6266, device='cuda:0', grad_fn=<NllLossBackward>) 171\n",
            "tensor(0.6118, device='cuda:0', grad_fn=<NllLossBackward>) 172\n",
            "tensor(0.6130, device='cuda:0', grad_fn=<NllLossBackward>) 173\n",
            "tensor(0.6287, device='cuda:0', grad_fn=<NllLossBackward>) 174\n",
            "tensor(0.6371, device='cuda:0', grad_fn=<NllLossBackward>) 175\n",
            "tensor(0.5890, device='cuda:0', grad_fn=<NllLossBackward>) 176\n",
            "tensor(0.6287, device='cuda:0', grad_fn=<NllLossBackward>) 177\n",
            "tensor(0.6061, device='cuda:0', grad_fn=<NllLossBackward>) 178\n",
            "tensor(0.6281, device='cuda:0', grad_fn=<NllLossBackward>) 179\n",
            "tensor(0.6307, device='cuda:0', grad_fn=<NllLossBackward>) 180\n",
            "tensor(0.5785, device='cuda:0', grad_fn=<NllLossBackward>) 181\n",
            "tensor(0.6054, device='cuda:0', grad_fn=<NllLossBackward>) 182\n",
            "tensor(0.6298, device='cuda:0', grad_fn=<NllLossBackward>) 183\n",
            "tensor(0.5991, device='cuda:0', grad_fn=<NllLossBackward>) 184\n",
            "tensor(0.5993, device='cuda:0', grad_fn=<NllLossBackward>) 185\n",
            "tensor(0.5891, device='cuda:0', grad_fn=<NllLossBackward>) 186\n",
            "tensor(0.6131, device='cuda:0', grad_fn=<NllLossBackward>) 187\n",
            "tensor(0.6053, device='cuda:0', grad_fn=<NllLossBackward>) 188\n",
            "tensor(0.5985, device='cuda:0', grad_fn=<NllLossBackward>) 189\n",
            "tensor(0.6336, device='cuda:0', grad_fn=<NllLossBackward>) 190\n",
            "tensor(0.5908, device='cuda:0', grad_fn=<NllLossBackward>) 191\n",
            "tensor(0.6470, device='cuda:0', grad_fn=<NllLossBackward>) 192\n",
            "tensor(0.6208, device='cuda:0', grad_fn=<NllLossBackward>) 193\n",
            "tensor(0.6069, device='cuda:0', grad_fn=<NllLossBackward>) 194\n",
            "tensor(0.6039, device='cuda:0', grad_fn=<NllLossBackward>) 195\n",
            "tensor(0.6014, device='cuda:0', grad_fn=<NllLossBackward>) 196\n",
            "tensor(0.6249, device='cuda:0', grad_fn=<NllLossBackward>) 197\n",
            "tensor(0.6044, device='cuda:0', grad_fn=<NllLossBackward>) 198\n",
            "tensor(0.6828, device='cuda:0', grad_fn=<NllLossBackward>) 199\n",
            "tensor(0.6603, device='cuda:0', grad_fn=<NllLossBackward>) 200\n",
            "tensor(0.6126, device='cuda:0', grad_fn=<NllLossBackward>) 201\n",
            "tensor(0.6230, device='cuda:0', grad_fn=<NllLossBackward>) 202\n",
            "tensor(0.6221, device='cuda:0', grad_fn=<NllLossBackward>) 203\n",
            "tensor(0.6925, device='cuda:0', grad_fn=<NllLossBackward>) 204\n",
            "tensor(0.5828, device='cuda:0', grad_fn=<NllLossBackward>) 205\n",
            "tensor(0.6221, device='cuda:0', grad_fn=<NllLossBackward>) 206\n",
            "tensor(0.6071, device='cuda:0', grad_fn=<NllLossBackward>) 207\n",
            "tensor(0.6070, device='cuda:0', grad_fn=<NllLossBackward>) 208\n",
            "tensor(0.6354, device='cuda:0', grad_fn=<NllLossBackward>) 209\n",
            "tensor(0.6581, device='cuda:0', grad_fn=<NllLossBackward>) 210\n",
            "tensor(0.6145, device='cuda:0', grad_fn=<NllLossBackward>) 211\n",
            "tensor(0.6042, device='cuda:0', grad_fn=<NllLossBackward>) 212\n",
            "tensor(0.6109, device='cuda:0', grad_fn=<NllLossBackward>) 213\n",
            "tensor(0.6074, device='cuda:0', grad_fn=<NllLossBackward>) 214\n",
            "tensor(0.6049, device='cuda:0', grad_fn=<NllLossBackward>) 215\n",
            "tensor(0.6063, device='cuda:0', grad_fn=<NllLossBackward>) 216\n",
            "tensor(0.5952, device='cuda:0', grad_fn=<NllLossBackward>) 217\n",
            "tensor(0.6028, device='cuda:0', grad_fn=<NllLossBackward>) 218\n",
            "tensor(0.5991, device='cuda:0', grad_fn=<NllLossBackward>) 219\n",
            "tensor(0.6302, device='cuda:0', grad_fn=<NllLossBackward>) 220\n",
            "tensor(0.6194, device='cuda:0', grad_fn=<NllLossBackward>) 221\n",
            "tensor(0.6698, device='cuda:0', grad_fn=<NllLossBackward>) 222\n",
            "tensor(0.6012, device='cuda:0', grad_fn=<NllLossBackward>) 223\n",
            "tensor(0.6361, device='cuda:0', grad_fn=<NllLossBackward>) 224\n",
            "tensor(0.6117, device='cuda:0', grad_fn=<NllLossBackward>) 225\n",
            "tensor(0.6202, device='cuda:0', grad_fn=<NllLossBackward>) 226\n",
            "tensor(0.6065, device='cuda:0', grad_fn=<NllLossBackward>) 227\n",
            "tensor(0.6193, device='cuda:0', grad_fn=<NllLossBackward>) 228\n",
            "tensor(0.6103, device='cuda:0', grad_fn=<NllLossBackward>) 229\n",
            "tensor(0.6028, device='cuda:0', grad_fn=<NllLossBackward>) 230\n",
            "tensor(0.6476, device='cuda:0', grad_fn=<NllLossBackward>) 231\n",
            "tensor(0.6405, device='cuda:0', grad_fn=<NllLossBackward>) 232\n",
            "tensor(0.5958, device='cuda:0', grad_fn=<NllLossBackward>) 233\n",
            "tensor(0.6198, device='cuda:0', grad_fn=<NllLossBackward>) 234\n",
            "tensor(0.5878, device='cuda:0', grad_fn=<NllLossBackward>) 235\n",
            "tensor(0.6083, device='cuda:0', grad_fn=<NllLossBackward>) 236\n",
            "tensor(0.6142, device='cuda:0', grad_fn=<NllLossBackward>) 237\n",
            "tensor(0.6222, device='cuda:0', grad_fn=<NllLossBackward>) 238\n",
            "tensor(0.5742, device='cuda:0', grad_fn=<NllLossBackward>) 239\n",
            "tensor(0.5842, device='cuda:0', grad_fn=<NllLossBackward>) 240\n",
            "tensor(0.6377, device='cuda:0', grad_fn=<NllLossBackward>) 241\n",
            "tensor(0.6279, device='cuda:0', grad_fn=<NllLossBackward>) 242\n",
            "tensor(0.6197, device='cuda:0', grad_fn=<NllLossBackward>) 243\n",
            "tensor(0.6221, device='cuda:0', grad_fn=<NllLossBackward>) 244\n",
            "tensor(0.5922, device='cuda:0', grad_fn=<NllLossBackward>) 245\n",
            "tensor(0.5878, device='cuda:0', grad_fn=<NllLossBackward>) 246\n",
            "tensor(0.6471, device='cuda:0', grad_fn=<NllLossBackward>) 247\n",
            "tensor(0.6924, device='cuda:0', grad_fn=<NllLossBackward>) 248\n",
            "tensor(0.6023, device='cuda:0', grad_fn=<NllLossBackward>) 249\n",
            "tensor(0.5765, device='cuda:0', grad_fn=<NllLossBackward>) 250\n",
            "tensor(0.5970, device='cuda:0', grad_fn=<NllLossBackward>) 251\n",
            "tensor(0.5996, device='cuda:0', grad_fn=<NllLossBackward>) 252\n",
            "tensor(0.6138, device='cuda:0', grad_fn=<NllLossBackward>) 253\n",
            "tensor(0.5861, device='cuda:0', grad_fn=<NllLossBackward>) 254\n",
            "tensor(0.5939, device='cuda:0', grad_fn=<NllLossBackward>) 255\n",
            "tensor(0.5938, device='cuda:0', grad_fn=<NllLossBackward>) 256\n",
            "tensor(0.6149, device='cuda:0', grad_fn=<NllLossBackward>) 257\n",
            "tensor(0.5863, device='cuda:0', grad_fn=<NllLossBackward>) 258\n",
            "tensor(0.6091, device='cuda:0', grad_fn=<NllLossBackward>) 259\n",
            "tensor(0.6474, device='cuda:0', grad_fn=<NllLossBackward>) 260\n",
            "tensor(0.6377, device='cuda:0', grad_fn=<NllLossBackward>) 261\n",
            "tensor(0.6079, device='cuda:0', grad_fn=<NllLossBackward>) 262\n",
            "tensor(0.5916, device='cuda:0', grad_fn=<NllLossBackward>) 263\n",
            "tensor(0.5849, device='cuda:0', grad_fn=<NllLossBackward>) 264\n",
            "tensor(0.6022, device='cuda:0', grad_fn=<NllLossBackward>) 265\n",
            "tensor(0.6356, device='cuda:0', grad_fn=<NllLossBackward>) 266\n",
            "tensor(0.5946, device='cuda:0', grad_fn=<NllLossBackward>) 267\n",
            "tensor(0.6410, device='cuda:0', grad_fn=<NllLossBackward>) 268\n",
            "tensor(0.6043, device='cuda:0', grad_fn=<NllLossBackward>) 269\n",
            "tensor(0.5932, device='cuda:0', grad_fn=<NllLossBackward>) 270\n",
            "tensor(0.6176, device='cuda:0', grad_fn=<NllLossBackward>) 271\n",
            "tensor(0.6038, device='cuda:0', grad_fn=<NllLossBackward>) 272\n",
            "tensor(0.5819, device='cuda:0', grad_fn=<NllLossBackward>) 273\n",
            "tensor(0.5667, device='cuda:0', grad_fn=<NllLossBackward>) 274\n",
            "tensor(0.6174, device='cuda:0', grad_fn=<NllLossBackward>) 275\n",
            "tensor(0.6122, device='cuda:0', grad_fn=<NllLossBackward>) 276\n",
            "tensor(0.6603, device='cuda:0', grad_fn=<NllLossBackward>) 277\n",
            "tensor(0.6063, device='cuda:0', grad_fn=<NllLossBackward>) 278\n",
            "tensor(0.6297, device='cuda:0', grad_fn=<NllLossBackward>) 279\n",
            "tensor(0.6434, device='cuda:0', grad_fn=<NllLossBackward>) 280\n",
            "tensor(0.6626, device='cuda:0', grad_fn=<NllLossBackward>) 281\n",
            "tensor(0.6077, device='cuda:0', grad_fn=<NllLossBackward>) 282\n",
            "tensor(0.6325, device='cuda:0', grad_fn=<NllLossBackward>) 283\n",
            "tensor(0.5949, device='cuda:0', grad_fn=<NllLossBackward>) 284\n",
            "tensor(0.5861, device='cuda:0', grad_fn=<NllLossBackward>) 285\n",
            "tensor(0.6315, device='cuda:0', grad_fn=<NllLossBackward>) 286\n",
            "tensor(0.5998, device='cuda:0', grad_fn=<NllLossBackward>) 287\n",
            "tensor(0.5899, device='cuda:0', grad_fn=<NllLossBackward>) 288\n",
            "tensor(0.5834, device='cuda:0', grad_fn=<NllLossBackward>) 289\n",
            "tensor(0.6091, device='cuda:0', grad_fn=<NllLossBackward>) 290\n",
            "tensor(0.6004, device='cuda:0', grad_fn=<NllLossBackward>) 291\n",
            "tensor(0.6031, device='cuda:0', grad_fn=<NllLossBackward>) 292\n",
            "tensor(0.5984, device='cuda:0', grad_fn=<NllLossBackward>) 293\n",
            "tensor(0.6400, device='cuda:0', grad_fn=<NllLossBackward>) 294\n",
            "tensor(0.6137, device='cuda:0', grad_fn=<NllLossBackward>) 295\n",
            "tensor(0.5675, device='cuda:0', grad_fn=<NllLossBackward>) 296\n",
            "tensor(0.6016, device='cuda:0', grad_fn=<NllLossBackward>) 297\n",
            "tensor(0.5869, device='cuda:0', grad_fn=<NllLossBackward>) 298\n",
            "tensor(0.6090, device='cuda:0', grad_fn=<NllLossBackward>) 299\n",
            "tensor(0.6161, device='cuda:0', grad_fn=<NllLossBackward>) 300\n",
            "tensor(0.6481, device='cuda:0', grad_fn=<NllLossBackward>) 301\n",
            "tensor(0.5743, device='cuda:0', grad_fn=<NllLossBackward>) 302\n",
            "tensor(0.5937, device='cuda:0', grad_fn=<NllLossBackward>) 303\n",
            "tensor(0.5677, device='cuda:0', grad_fn=<NllLossBackward>) 304\n",
            "tensor(0.6399, device='cuda:0', grad_fn=<NllLossBackward>) 305\n",
            "tensor(0.6242, device='cuda:0', grad_fn=<NllLossBackward>) 306\n",
            "tensor(0.6301, device='cuda:0', grad_fn=<NllLossBackward>) 307\n",
            "tensor(0.5712, device='cuda:0', grad_fn=<NllLossBackward>) 308\n",
            "tensor(0.6139, device='cuda:0', grad_fn=<NllLossBackward>) 309\n",
            "tensor(0.6210, device='cuda:0', grad_fn=<NllLossBackward>) 310\n",
            "tensor(0.5981, device='cuda:0', grad_fn=<NllLossBackward>) 311\n",
            "tensor(0.6027, device='cuda:0', grad_fn=<NllLossBackward>) 312\n",
            "tensor(0.6106, device='cuda:0', grad_fn=<NllLossBackward>) 313\n",
            "tensor(0.6136, device='cuda:0', grad_fn=<NllLossBackward>) 314\n",
            "tensor(0.6054, device='cuda:0', grad_fn=<NllLossBackward>) 315\n",
            "tensor(0.5793, device='cuda:0', grad_fn=<NllLossBackward>) 316\n",
            "tensor(0.6369, device='cuda:0', grad_fn=<NllLossBackward>) 317\n",
            "tensor(0.6173, device='cuda:0', grad_fn=<NllLossBackward>) 318\n",
            "tensor(0.6482, device='cuda:0', grad_fn=<NllLossBackward>) 319\n",
            "tensor(0.5802, device='cuda:0', grad_fn=<NllLossBackward>) 320\n",
            "tensor(0.6292, device='cuda:0', grad_fn=<NllLossBackward>) 321\n",
            "tensor(0.6294, device='cuda:0', grad_fn=<NllLossBackward>) 322\n",
            "tensor(0.6452, device='cuda:0', grad_fn=<NllLossBackward>) 323\n",
            "tensor(0.6350, device='cuda:0', grad_fn=<NllLossBackward>) 324\n",
            "tensor(0.6167, device='cuda:0', grad_fn=<NllLossBackward>) 325\n",
            "tensor(0.5903, device='cuda:0', grad_fn=<NllLossBackward>) 326\n",
            "tensor(0.6288, device='cuda:0', grad_fn=<NllLossBackward>) 327\n",
            "tensor(0.5947, device='cuda:0', grad_fn=<NllLossBackward>) 328\n",
            "tensor(0.6469, device='cuda:0', grad_fn=<NllLossBackward>) 329\n",
            "tensor(0.5882, device='cuda:0', grad_fn=<NllLossBackward>) 330\n",
            "tensor(0.6743, device='cuda:0', grad_fn=<NllLossBackward>) 331\n",
            "tensor(0.6764, device='cuda:0', grad_fn=<NllLossBackward>) 332\n",
            "tensor(0.6274, device='cuda:0', grad_fn=<NllLossBackward>) 333\n",
            "tensor(0.6288, device='cuda:0', grad_fn=<NllLossBackward>) 334\n",
            "tensor(0.5883, device='cuda:0', grad_fn=<NllLossBackward>) 335\n",
            "tensor(0.6033, device='cuda:0', grad_fn=<NllLossBackward>) 336\n",
            "tensor(0.6399, device='cuda:0', grad_fn=<NllLossBackward>) 337\n",
            "tensor(0.5606, device='cuda:0', grad_fn=<NllLossBackward>) 338\n",
            "tensor(0.5639, device='cuda:0', grad_fn=<NllLossBackward>) 339\n",
            "tensor(0.5348, device='cuda:0', grad_fn=<NllLossBackward>) 340\n",
            "tensor(0.6025, device='cuda:0', grad_fn=<NllLossBackward>) 341\n",
            "tensor(0.6907, device='cuda:0', grad_fn=<NllLossBackward>) 342\n",
            "tensor(0.7208, device='cuda:0', grad_fn=<NllLossBackward>) 343\n",
            "tensor(0.6387, device='cuda:0', grad_fn=<NllLossBackward>) 344\n",
            "tensor(0.6261, device='cuda:0', grad_fn=<NllLossBackward>) 345\n",
            "tensor(0.5993, device='cuda:0', grad_fn=<NllLossBackward>) 346\n",
            "tensor(0.6159, device='cuda:0', grad_fn=<NllLossBackward>) 347\n",
            "tensor(0.6079, device='cuda:0', grad_fn=<NllLossBackward>) 348\n",
            "tensor(0.5845, device='cuda:0', grad_fn=<NllLossBackward>) 349\n",
            "tensor(0.5896, device='cuda:0', grad_fn=<NllLossBackward>) 350\n",
            "tensor(0.5953, device='cuda:0', grad_fn=<NllLossBackward>) 351\n",
            "tensor(0.6158, device='cuda:0', grad_fn=<NllLossBackward>) 352\n",
            "tensor(0.6112, device='cuda:0', grad_fn=<NllLossBackward>) 353\n",
            "tensor(0.5880, device='cuda:0', grad_fn=<NllLossBackward>) 354\n",
            "tensor(0.6128, device='cuda:0', grad_fn=<NllLossBackward>) 355\n",
            "tensor(0.6201, device='cuda:0', grad_fn=<NllLossBackward>) 356\n",
            "tensor(0.6434, device='cuda:0', grad_fn=<NllLossBackward>) 357\n",
            "tensor(0.6613, device='cuda:0', grad_fn=<NllLossBackward>) 358\n",
            "tensor(0.6211, device='cuda:0', grad_fn=<NllLossBackward>) 359\n",
            "tensor(0.6951, device='cuda:0', grad_fn=<NllLossBackward>) 360\n",
            "tensor(0.6124, device='cuda:0', grad_fn=<NllLossBackward>) 361\n",
            "tensor(0.6222, device='cuda:0', grad_fn=<NllLossBackward>) 362\n",
            "tensor(0.6277, device='cuda:0', grad_fn=<NllLossBackward>) 363\n",
            "tensor(0.6170, device='cuda:0', grad_fn=<NllLossBackward>) 364\n",
            "tensor(0.6288, device='cuda:0', grad_fn=<NllLossBackward>) 365\n",
            "tensor(0.5928, device='cuda:0', grad_fn=<NllLossBackward>) 366\n",
            "tensor(0.5878, device='cuda:0', grad_fn=<NllLossBackward>) 367\n",
            "tensor(0.6154, device='cuda:0', grad_fn=<NllLossBackward>) 368\n",
            "tensor(0.6210, device='cuda:0', grad_fn=<NllLossBackward>) 369\n",
            "tensor(0.6135, device='cuda:0', grad_fn=<NllLossBackward>) 370\n",
            "tensor(0.6224, device='cuda:0', grad_fn=<NllLossBackward>) 371\n",
            "tensor(0.5781, device='cuda:0', grad_fn=<NllLossBackward>) 372\n",
            "tensor(0.6614, device='cuda:0', grad_fn=<NllLossBackward>) 373\n",
            "tensor(0.6139, device='cuda:0', grad_fn=<NllLossBackward>) 374\n",
            "tensor(0.5886, device='cuda:0', grad_fn=<NllLossBackward>) 375\n",
            "tensor(0.5785, device='cuda:0', grad_fn=<NllLossBackward>) 376\n",
            "tensor(0.5900, device='cuda:0', grad_fn=<NllLossBackward>) 377\n",
            "tensor(0.6222, device='cuda:0', grad_fn=<NllLossBackward>) 378\n",
            "tensor(0.5680, device='cuda:0', grad_fn=<NllLossBackward>) 379\n",
            "tensor(0.5963, device='cuda:0', grad_fn=<NllLossBackward>) 380\n",
            "tensor(0.6196, device='cuda:0', grad_fn=<NllLossBackward>) 381\n",
            "tensor(0.5980, device='cuda:0', grad_fn=<NllLossBackward>) 382\n",
            "tensor(0.6322, device='cuda:0', grad_fn=<NllLossBackward>) 383\n",
            "tensor(0.5519, device='cuda:0', grad_fn=<NllLossBackward>) 384\n",
            "tensor(0.6187, device='cuda:0', grad_fn=<NllLossBackward>) 385\n",
            "tensor(0.5386, device='cuda:0', grad_fn=<NllLossBackward>) 386\n",
            "tensor(0.6122, device='cuda:0', grad_fn=<NllLossBackward>) 387\n",
            "tensor(0.6148, device='cuda:0', grad_fn=<NllLossBackward>) 388\n",
            "tensor(0.5607, device='cuda:0', grad_fn=<NllLossBackward>) 389\n",
            "tensor(0.6161, device='cuda:0', grad_fn=<NllLossBackward>) 390\n",
            "tensor(0.6348, device='cuda:0', grad_fn=<NllLossBackward>) 391\n",
            "tensor(0.5873, device='cuda:0', grad_fn=<NllLossBackward>) 392\n",
            "tensor(0.5613, device='cuda:0', grad_fn=<NllLossBackward>) 393\n",
            "tensor(0.6296, device='cuda:0', grad_fn=<NllLossBackward>) 394\n",
            "tensor(0.6005, device='cuda:0', grad_fn=<NllLossBackward>) 395\n",
            "tensor(0.6336, device='cuda:0', grad_fn=<NllLossBackward>) 396\n",
            "tensor(0.5753, device='cuda:0', grad_fn=<NllLossBackward>) 397\n",
            "tensor(0.5910, device='cuda:0', grad_fn=<NllLossBackward>) 398\n",
            "tensor(0.6002, device='cuda:0', grad_fn=<NllLossBackward>) 399\n",
            "tensor(0.6116, device='cuda:0', grad_fn=<NllLossBackward>) 400\n",
            "tensor(0.6023, device='cuda:0', grad_fn=<NllLossBackward>) 401\n",
            "tensor(0.5747, device='cuda:0', grad_fn=<NllLossBackward>) 402\n",
            "tensor(0.5709, device='cuda:0', grad_fn=<NllLossBackward>) 403\n",
            "tensor(0.5991, device='cuda:0', grad_fn=<NllLossBackward>) 404\n",
            "tensor(0.5993, device='cuda:0', grad_fn=<NllLossBackward>) 405\n",
            "tensor(0.6309, device='cuda:0', grad_fn=<NllLossBackward>) 406\n",
            "tensor(0.6411, device='cuda:0', grad_fn=<NllLossBackward>) 407\n",
            "tensor(0.5980, device='cuda:0', grad_fn=<NllLossBackward>) 408\n",
            "tensor(0.5940, device='cuda:0', grad_fn=<NllLossBackward>) 409\n",
            "tensor(0.5941, device='cuda:0', grad_fn=<NllLossBackward>) 410\n",
            "tensor(0.5548, device='cuda:0', grad_fn=<NllLossBackward>) 411\n",
            "tensor(0.5989, device='cuda:0', grad_fn=<NllLossBackward>) 412\n",
            "tensor(0.5986, device='cuda:0', grad_fn=<NllLossBackward>) 413\n",
            "tensor(0.5520, device='cuda:0', grad_fn=<NllLossBackward>) 414\n",
            "tensor(0.6366, device='cuda:0', grad_fn=<NllLossBackward>) 415\n",
            "tensor(0.6222, device='cuda:0', grad_fn=<NllLossBackward>) 416\n",
            "tensor(0.5937, device='cuda:0', grad_fn=<NllLossBackward>) 417\n",
            "tensor(0.6034, device='cuda:0', grad_fn=<NllLossBackward>) 418\n",
            "tensor(0.5946, device='cuda:0', grad_fn=<NllLossBackward>) 419\n",
            "tensor(0.6055, device='cuda:0', grad_fn=<NllLossBackward>) 420\n",
            "tensor(0.6237, device='cuda:0', grad_fn=<NllLossBackward>) 421\n",
            "tensor(0.6012, device='cuda:0', grad_fn=<NllLossBackward>) 422\n",
            "tensor(0.5946, device='cuda:0', grad_fn=<NllLossBackward>) 423\n",
            "tensor(0.5893, device='cuda:0', grad_fn=<NllLossBackward>) 424\n",
            "tensor(0.6744, device='cuda:0', grad_fn=<NllLossBackward>) 425\n",
            "tensor(0.5940, device='cuda:0', grad_fn=<NllLossBackward>) 426\n",
            "tensor(0.6174, device='cuda:0', grad_fn=<NllLossBackward>) 427\n",
            "tensor(0.6146, device='cuda:0', grad_fn=<NllLossBackward>) 428\n",
            "tensor(0.6417, device='cuda:0', grad_fn=<NllLossBackward>) 429\n",
            "tensor(0.6078, device='cuda:0', grad_fn=<NllLossBackward>) 430\n",
            "tensor(0.6004, device='cuda:0', grad_fn=<NllLossBackward>) 431\n",
            "tensor(0.5789, device='cuda:0', grad_fn=<NllLossBackward>) 432\n",
            "tensor(0.6709, device='cuda:0', grad_fn=<NllLossBackward>) 433\n",
            "tensor(0.6038, device='cuda:0', grad_fn=<NllLossBackward>) 434\n",
            "tensor(0.5759, device='cuda:0', grad_fn=<NllLossBackward>) 435\n",
            "tensor(0.5996, device='cuda:0', grad_fn=<NllLossBackward>) 436\n",
            "tensor(0.5579, device='cuda:0', grad_fn=<NllLossBackward>) 437\n",
            "tensor(0.6111, device='cuda:0', grad_fn=<NllLossBackward>) 438\n",
            "tensor(0.6026, device='cuda:0', grad_fn=<NllLossBackward>) 439\n",
            "tensor(0.6104, device='cuda:0', grad_fn=<NllLossBackward>) 440\n",
            "tensor(0.6074, device='cuda:0', grad_fn=<NllLossBackward>) 441\n",
            "tensor(0.6028, device='cuda:0', grad_fn=<NllLossBackward>) 442\n",
            "tensor(0.6164, device='cuda:0', grad_fn=<NllLossBackward>) 443\n",
            "tensor(0.5799, device='cuda:0', grad_fn=<NllLossBackward>) 444\n",
            "tensor(0.6064, device='cuda:0', grad_fn=<NllLossBackward>) 445\n",
            "tensor(0.6396, device='cuda:0', grad_fn=<NllLossBackward>) 446\n",
            "tensor(0.6139, device='cuda:0', grad_fn=<NllLossBackward>) 447\n",
            "tensor(0.5928, device='cuda:0', grad_fn=<NllLossBackward>) 448\n",
            "tensor(0.6239, device='cuda:0', grad_fn=<NllLossBackward>) 449\n",
            "tensor(0.6254, device='cuda:0', grad_fn=<NllLossBackward>) 450\n",
            "tensor(0.6135, device='cuda:0', grad_fn=<NllLossBackward>) 451\n",
            "tensor(0.5933, device='cuda:0', grad_fn=<NllLossBackward>) 452\n",
            "tensor(0.6066, device='cuda:0', grad_fn=<NllLossBackward>) 453\n",
            "tensor(0.5785, device='cuda:0', grad_fn=<NllLossBackward>) 454\n",
            "tensor(0.6384, device='cuda:0', grad_fn=<NllLossBackward>) 455\n",
            "tensor(0.6196, device='cuda:0', grad_fn=<NllLossBackward>) 456\n",
            "tensor(0.5577, device='cuda:0', grad_fn=<NllLossBackward>) 457\n",
            "tensor(0.5826, device='cuda:0', grad_fn=<NllLossBackward>) 458\n",
            "tensor(0.6229, device='cuda:0', grad_fn=<NllLossBackward>) 459\n",
            "tensor(0.5974, device='cuda:0', grad_fn=<NllLossBackward>) 460\n",
            "tensor(0.5790, device='cuda:0', grad_fn=<NllLossBackward>) 461\n",
            "tensor(0.6191, device='cuda:0', grad_fn=<NllLossBackward>) 462\n",
            "tensor(0.6083, device='cuda:0', grad_fn=<NllLossBackward>) 463\n",
            "tensor(0.6184, device='cuda:0', grad_fn=<NllLossBackward>) 464\n",
            "tensor(0.6363, device='cuda:0', grad_fn=<NllLossBackward>) 465\n",
            "tensor(0.6548, device='cuda:0', grad_fn=<NllLossBackward>) 466\n",
            "tensor(0.6587, device='cuda:0', grad_fn=<NllLossBackward>) 467\n",
            "tensor(0.5305, device='cuda:0', grad_fn=<NllLossBackward>) 468\n",
            "tensor(0.6100, device='cuda:0', grad_fn=<NllLossBackward>) 469\n",
            "tensor(0.5940, device='cuda:0', grad_fn=<NllLossBackward>) 470\n",
            "tensor(0.6208, device='cuda:0', grad_fn=<NllLossBackward>) 471\n",
            "tensor(0.6071, device='cuda:0', grad_fn=<NllLossBackward>) 472\n",
            "tensor(0.5846, device='cuda:0', grad_fn=<NllLossBackward>) 473\n",
            "tensor(0.5826, device='cuda:0', grad_fn=<NllLossBackward>) 474\n",
            "tensor(0.6354, device='cuda:0', grad_fn=<NllLossBackward>) 475\n",
            "tensor(0.6184, device='cuda:0', grad_fn=<NllLossBackward>) 476\n",
            "tensor(0.6143, device='cuda:0', grad_fn=<NllLossBackward>) 477\n",
            "tensor(0.6139, device='cuda:0', grad_fn=<NllLossBackward>) 478\n",
            "tensor(0.5913, device='cuda:0', grad_fn=<NllLossBackward>) 479\n",
            "tensor(0.6006, device='cuda:0', grad_fn=<NllLossBackward>) 480\n",
            "tensor(0.5964, device='cuda:0', grad_fn=<NllLossBackward>) 481\n",
            "tensor(0.6295, device='cuda:0', grad_fn=<NllLossBackward>) 482\n",
            "tensor(0.6000, device='cuda:0', grad_fn=<NllLossBackward>) 483\n",
            "tensor(0.6053, device='cuda:0', grad_fn=<NllLossBackward>) 484\n",
            "tensor(0.5681, device='cuda:0', grad_fn=<NllLossBackward>) 485\n",
            "tensor(0.6311, device='cuda:0', grad_fn=<NllLossBackward>) 486\n",
            "tensor(0.5944, device='cuda:0', grad_fn=<NllLossBackward>) 487\n",
            "tensor(0.6095, device='cuda:0', grad_fn=<NllLossBackward>) 488\n",
            "tensor(0.5689, device='cuda:0', grad_fn=<NllLossBackward>) 489\n",
            "tensor(0.5645, device='cuda:0', grad_fn=<NllLossBackward>) 490\n",
            "tensor(0.5906, device='cuda:0', grad_fn=<NllLossBackward>) 491\n",
            "tensor(0.6101, device='cuda:0', grad_fn=<NllLossBackward>) 492\n",
            "tensor(0.5992, device='cuda:0', grad_fn=<NllLossBackward>) 493\n",
            "tensor(0.6143, device='cuda:0', grad_fn=<NllLossBackward>) 494\n",
            "tensor(0.5788, device='cuda:0', grad_fn=<NllLossBackward>) 495\n",
            "tensor(0.6202, device='cuda:0', grad_fn=<NllLossBackward>) 496\n",
            "tensor(0.5862, device='cuda:0', grad_fn=<NllLossBackward>) 497\n",
            "tensor(0.6144, device='cuda:0', grad_fn=<NllLossBackward>) 498\n",
            "tensor(0.6105, device='cuda:0', grad_fn=<NllLossBackward>) 499\n",
            "tensor(0.6283, device='cuda:0', grad_fn=<NllLossBackward>) 500\n",
            "tensor(0.5684, device='cuda:0', grad_fn=<NllLossBackward>) 501\n",
            "tensor(0.5881, device='cuda:0', grad_fn=<NllLossBackward>) 502\n",
            "tensor(0.6863, device='cuda:0', grad_fn=<NllLossBackward>) 503\n",
            "tensor(0.6510, device='cuda:0', grad_fn=<NllLossBackward>) 504\n",
            "tensor(0.5620, device='cuda:0', grad_fn=<NllLossBackward>) 505\n",
            "tensor(0.5843, device='cuda:0', grad_fn=<NllLossBackward>) 506\n",
            "tensor(0.5862, device='cuda:0', grad_fn=<NllLossBackward>) 507\n",
            "tensor(0.6290, device='cuda:0', grad_fn=<NllLossBackward>) 508\n",
            "tensor(0.5632, device='cuda:0', grad_fn=<NllLossBackward>) 509\n",
            "tensor(0.6361, device='cuda:0', grad_fn=<NllLossBackward>) 510\n",
            "tensor(0.6101, device='cuda:0', grad_fn=<NllLossBackward>) 511\n",
            "tensor(0.6183, device='cuda:0', grad_fn=<NllLossBackward>) 512\n",
            "tensor(0.5788, device='cuda:0', grad_fn=<NllLossBackward>) 513\n",
            "tensor(0.5440, device='cuda:0', grad_fn=<NllLossBackward>) 514\n",
            "tensor(0.5674, device='cuda:0', grad_fn=<NllLossBackward>) 515\n",
            "tensor(0.5969, device='cuda:0', grad_fn=<NllLossBackward>) 516\n",
            "tensor(0.5853, device='cuda:0', grad_fn=<NllLossBackward>) 517\n",
            "tensor(0.6357, device='cuda:0', grad_fn=<NllLossBackward>) 518\n",
            "tensor(0.6067, device='cuda:0', grad_fn=<NllLossBackward>) 519\n",
            "tensor(0.6593, device='cuda:0', grad_fn=<NllLossBackward>) 520\n",
            "tensor(0.6166, device='cuda:0', grad_fn=<NllLossBackward>) 521\n",
            "tensor(0.7195, device='cuda:0', grad_fn=<NllLossBackward>) 522\n",
            "tensor(0.6172, device='cuda:0', grad_fn=<NllLossBackward>) 523\n",
            "tensor(0.6102, device='cuda:0', grad_fn=<NllLossBackward>) 524\n",
            "tensor(0.5454, device='cuda:0', grad_fn=<NllLossBackward>) 525\n",
            "tensor(0.5910, device='cuda:0', grad_fn=<NllLossBackward>) 526\n",
            "tensor(0.5476, device='cuda:0', grad_fn=<NllLossBackward>) 527\n",
            "tensor(0.6235, device='cuda:0', grad_fn=<NllLossBackward>) 528\n",
            "tensor(0.6171, device='cuda:0', grad_fn=<NllLossBackward>) 529\n",
            "tensor(0.6154, device='cuda:0', grad_fn=<NllLossBackward>) 530\n",
            "tensor(0.6070, device='cuda:0', grad_fn=<NllLossBackward>) 531\n",
            "tensor(0.6071, device='cuda:0', grad_fn=<NllLossBackward>) 532\n",
            "tensor(0.6021, device='cuda:0', grad_fn=<NllLossBackward>) 533\n",
            "tensor(0.5901, device='cuda:0', grad_fn=<NllLossBackward>) 534\n",
            "tensor(0.6192, device='cuda:0', grad_fn=<NllLossBackward>) 535\n",
            "tensor(0.5917, device='cuda:0', grad_fn=<NllLossBackward>) 536\n",
            "tensor(0.5757, device='cuda:0', grad_fn=<NllLossBackward>) 537\n",
            "tensor(0.5823, device='cuda:0', grad_fn=<NllLossBackward>) 538\n",
            "tensor(0.5781, device='cuda:0', grad_fn=<NllLossBackward>) 539\n",
            "tensor(0.5813, device='cuda:0', grad_fn=<NllLossBackward>) 540\n",
            "tensor(0.5872, device='cuda:0', grad_fn=<NllLossBackward>) 541\n",
            "tensor(0.6107, device='cuda:0', grad_fn=<NllLossBackward>) 542\n",
            "tensor(0.6305, device='cuda:0', grad_fn=<NllLossBackward>) 543\n",
            "tensor(0.6049, device='cuda:0', grad_fn=<NllLossBackward>) 544\n",
            "tensor(0.5526, device='cuda:0', grad_fn=<NllLossBackward>) 545\n",
            "tensor(0.6287, device='cuda:0', grad_fn=<NllLossBackward>) 546\n",
            "tensor(0.6259, device='cuda:0', grad_fn=<NllLossBackward>) 547\n",
            "tensor(0.5986, device='cuda:0', grad_fn=<NllLossBackward>) 548\n",
            "tensor(0.5774, device='cuda:0', grad_fn=<NllLossBackward>) 549\n",
            "tensor(0.6333, device='cuda:0', grad_fn=<NllLossBackward>) 550\n",
            "tensor(0.6128, device='cuda:0', grad_fn=<NllLossBackward>) 551\n",
            "tensor(0.6162, device='cuda:0', grad_fn=<NllLossBackward>) 552\n",
            "tensor(0.5796, device='cuda:0', grad_fn=<NllLossBackward>) 553\n",
            "tensor(0.6093, device='cuda:0', grad_fn=<NllLossBackward>) 554\n",
            "tensor(0.6164, device='cuda:0', grad_fn=<NllLossBackward>) 555\n",
            "tensor(0.6050, device='cuda:0', grad_fn=<NllLossBackward>) 556\n",
            "tensor(0.5961, device='cuda:0', grad_fn=<NllLossBackward>) 557\n",
            "tensor(0.6202, device='cuda:0', grad_fn=<NllLossBackward>) 558\n",
            "tensor(0.5926, device='cuda:0', grad_fn=<NllLossBackward>) 559\n",
            "tensor(0.6006, device='cuda:0', grad_fn=<NllLossBackward>) 560\n",
            "tensor(0.6150, device='cuda:0', grad_fn=<NllLossBackward>) 561\n",
            "tensor(0.6213, device='cuda:0', grad_fn=<NllLossBackward>) 562\n",
            "tensor(0.6059, device='cuda:0', grad_fn=<NllLossBackward>) 563\n",
            "tensor(0.6060, device='cuda:0', grad_fn=<NllLossBackward>) 564\n",
            "tensor(0.5646, device='cuda:0', grad_fn=<NllLossBackward>) 565\n",
            "tensor(0.5949, device='cuda:0', grad_fn=<NllLossBackward>) 566\n",
            "tensor(0.5755, device='cuda:0', grad_fn=<NllLossBackward>) 567\n",
            "tensor(0.5983, device='cuda:0', grad_fn=<NllLossBackward>) 568\n",
            "tensor(0.5649, device='cuda:0', grad_fn=<NllLossBackward>) 569\n",
            "tensor(0.6179, device='cuda:0', grad_fn=<NllLossBackward>) 570\n",
            "tensor(0.6389, device='cuda:0', grad_fn=<NllLossBackward>) 571\n",
            "tensor(0.6210, device='cuda:0', grad_fn=<NllLossBackward>) 572\n",
            "tensor(0.5985, device='cuda:0', grad_fn=<NllLossBackward>) 573\n",
            "tensor(0.6389, device='cuda:0', grad_fn=<NllLossBackward>) 574\n",
            "tensor(0.5927, device='cuda:0', grad_fn=<NllLossBackward>) 575\n",
            "tensor(0.6513, device='cuda:0', grad_fn=<NllLossBackward>) 576\n",
            "tensor(0.6265, device='cuda:0', grad_fn=<NllLossBackward>) 577\n",
            "tensor(0.5948, device='cuda:0', grad_fn=<NllLossBackward>) 578\n",
            "tensor(0.5728, device='cuda:0', grad_fn=<NllLossBackward>) 579\n",
            "tensor(0.6006, device='cuda:0', grad_fn=<NllLossBackward>) 580\n",
            "tensor(0.6138, device='cuda:0', grad_fn=<NllLossBackward>) 581\n",
            "tensor(0.5859, device='cuda:0', grad_fn=<NllLossBackward>) 582\n",
            "tensor(0.5584, device='cuda:0', grad_fn=<NllLossBackward>) 583\n",
            "tensor(0.6074, device='cuda:0', grad_fn=<NllLossBackward>) 584\n",
            "tensor(0.6319, device='cuda:0', grad_fn=<NllLossBackward>) 585\n",
            "tensor(0.5856, device='cuda:0', grad_fn=<NllLossBackward>) 586\n",
            "tensor(0.6662, device='cuda:0', grad_fn=<NllLossBackward>) 587\n",
            "tensor(0.5851, device='cuda:0', grad_fn=<NllLossBackward>) 588\n",
            "tensor(0.5728, device='cuda:0', grad_fn=<NllLossBackward>) 589\n",
            "tensor(0.6147, device='cuda:0', grad_fn=<NllLossBackward>) 590\n",
            "tensor(0.5782, device='cuda:0', grad_fn=<NllLossBackward>) 591\n",
            "tensor(0.6132, device='cuda:0', grad_fn=<NllLossBackward>) 592\n",
            "tensor(0.5935, device='cuda:0', grad_fn=<NllLossBackward>) 593\n",
            "tensor(0.5777, device='cuda:0', grad_fn=<NllLossBackward>) 594\n",
            "tensor(0.6127, device='cuda:0', grad_fn=<NllLossBackward>) 595\n",
            "tensor(0.6408, device='cuda:0', grad_fn=<NllLossBackward>) 596\n",
            "tensor(0.5866, device='cuda:0', grad_fn=<NllLossBackward>) 597\n",
            "tensor(0.6028, device='cuda:0', grad_fn=<NllLossBackward>) 598\n",
            "tensor(0.5944, device='cuda:0', grad_fn=<NllLossBackward>) 599\n",
            "tensor(0.5795, device='cuda:0', grad_fn=<NllLossBackward>) 600\n",
            "tensor(0.5533, device='cuda:0', grad_fn=<NllLossBackward>) 601\n",
            "tensor(0.6042, device='cuda:0', grad_fn=<NllLossBackward>) 602\n",
            "tensor(0.5976, device='cuda:0', grad_fn=<NllLossBackward>) 603\n",
            "tensor(0.5938, device='cuda:0', grad_fn=<NllLossBackward>) 604\n",
            "tensor(0.5327, device='cuda:0', grad_fn=<NllLossBackward>) 605\n",
            "tensor(0.5052, device='cuda:0', grad_fn=<NllLossBackward>) 606\n",
            "tensor(0.6151, device='cuda:0', grad_fn=<NllLossBackward>) 607\n",
            "tensor(0.5583, device='cuda:0', grad_fn=<NllLossBackward>) 608\n",
            "tensor(0.5944, device='cuda:0', grad_fn=<NllLossBackward>) 609\n",
            "tensor(0.5903, device='cuda:0', grad_fn=<NllLossBackward>) 610\n",
            "tensor(0.5973, device='cuda:0', grad_fn=<NllLossBackward>) 611\n",
            "tensor(0.5512, device='cuda:0', grad_fn=<NllLossBackward>) 612\n",
            "tensor(0.5882, device='cuda:0', grad_fn=<NllLossBackward>) 613\n",
            "tensor(0.6099, device='cuda:0', grad_fn=<NllLossBackward>) 614\n",
            "tensor(0.5736, device='cuda:0', grad_fn=<NllLossBackward>) 615\n",
            "tensor(0.5912, device='cuda:0', grad_fn=<NllLossBackward>) 616\n",
            "tensor(0.5885, device='cuda:0', grad_fn=<NllLossBackward>) 617\n",
            "tensor(0.6192, device='cuda:0', grad_fn=<NllLossBackward>) 618\n",
            "tensor(0.5983, device='cuda:0', grad_fn=<NllLossBackward>) 619\n",
            "tensor(0.5568, device='cuda:0', grad_fn=<NllLossBackward>) 620\n",
            "tensor(0.6600, device='cuda:0', grad_fn=<NllLossBackward>) 621\n",
            "tensor(0.6274, device='cuda:0', grad_fn=<NllLossBackward>) 622\n",
            "tensor(0.5636, device='cuda:0', grad_fn=<NllLossBackward>) 623\n",
            "tensor(0.5545, device='cuda:0', grad_fn=<NllLossBackward>) 624\n",
            "tensor(0.5765, device='cuda:0', grad_fn=<NllLossBackward>) 625\n",
            "tensor(0.6009, device='cuda:0', grad_fn=<NllLossBackward>) 626\n",
            "tensor(0.6605, device='cuda:0', grad_fn=<NllLossBackward>) 627\n",
            "tensor(0.6230, device='cuda:0', grad_fn=<NllLossBackward>) 628\n",
            "tensor(0.5576, device='cuda:0', grad_fn=<NllLossBackward>) 629\n",
            "tensor(0.5855, device='cuda:0', grad_fn=<NllLossBackward>) 630\n",
            "tensor(0.6434, device='cuda:0', grad_fn=<NllLossBackward>) 631\n",
            "tensor(0.5790, device='cuda:0', grad_fn=<NllLossBackward>) 632\n",
            "tensor(0.5427, device='cuda:0', grad_fn=<NllLossBackward>) 633\n",
            "tensor(0.5825, device='cuda:0', grad_fn=<NllLossBackward>) 634\n",
            "tensor(0.5876, device='cuda:0', grad_fn=<NllLossBackward>) 635\n",
            "tensor(0.5957, device='cuda:0', grad_fn=<NllLossBackward>) 636\n",
            "tensor(0.5466, device='cuda:0', grad_fn=<NllLossBackward>) 637\n",
            "tensor(0.6414, device='cuda:0', grad_fn=<NllLossBackward>) 638\n",
            "tensor(0.6362, device='cuda:0', grad_fn=<NllLossBackward>) 639\n",
            "tensor(0.5976, device='cuda:0', grad_fn=<NllLossBackward>) 640\n",
            "tensor(0.6110, device='cuda:0', grad_fn=<NllLossBackward>) 641\n",
            "tensor(0.5373, device='cuda:0', grad_fn=<NllLossBackward>) 642\n",
            "tensor(0.5116, device='cuda:0', grad_fn=<NllLossBackward>) 643\n",
            "tensor(0.6069, device='cuda:0', grad_fn=<NllLossBackward>) 644\n",
            "tensor(0.6164, device='cuda:0', grad_fn=<NllLossBackward>) 645\n",
            "tensor(0.5648, device='cuda:0', grad_fn=<NllLossBackward>) 646\n",
            "tensor(0.5853, device='cuda:0', grad_fn=<NllLossBackward>) 647\n",
            "tensor(0.6151, device='cuda:0', grad_fn=<NllLossBackward>) 648\n",
            "tensor(0.6266, device='cuda:0', grad_fn=<NllLossBackward>) 649\n",
            "tensor(0.5705, device='cuda:0', grad_fn=<NllLossBackward>) 650\n",
            "tensor(0.5608, device='cuda:0', grad_fn=<NllLossBackward>) 651\n",
            "tensor(0.5922, device='cuda:0', grad_fn=<NllLossBackward>) 652\n",
            "tensor(0.5938, device='cuda:0', grad_fn=<NllLossBackward>) 653\n",
            "tensor(0.5423, device='cuda:0', grad_fn=<NllLossBackward>) 654\n",
            "tensor(0.5938, device='cuda:0', grad_fn=<NllLossBackward>) 655\n",
            "tensor(0.5776, device='cuda:0', grad_fn=<NllLossBackward>) 656\n",
            "tensor(0.6105, device='cuda:0', grad_fn=<NllLossBackward>) 657\n",
            "tensor(0.5693, device='cuda:0', grad_fn=<NllLossBackward>) 658\n",
            "tensor(0.6200, device='cuda:0', grad_fn=<NllLossBackward>) 659\n",
            "tensor(0.6596, device='cuda:0', grad_fn=<NllLossBackward>) 660\n",
            "tensor(0.5798, device='cuda:0', grad_fn=<NllLossBackward>) 661\n",
            "tensor(0.5874, device='cuda:0', grad_fn=<NllLossBackward>) 662\n",
            "tensor(0.5510, device='cuda:0', grad_fn=<NllLossBackward>) 663\n",
            "tensor(0.6542, device='cuda:0', grad_fn=<NllLossBackward>) 664\n",
            "tensor(0.6460, device='cuda:0', grad_fn=<NllLossBackward>) 665\n",
            "tensor(0.6429, device='cuda:0', grad_fn=<NllLossBackward>) 666\n",
            "tensor(0.5964, device='cuda:0', grad_fn=<NllLossBackward>) 667\n",
            "tensor(0.5958, device='cuda:0', grad_fn=<NllLossBackward>) 668\n",
            "tensor(0.6127, device='cuda:0', grad_fn=<NllLossBackward>) 669\n",
            "tensor(0.6104, device='cuda:0', grad_fn=<NllLossBackward>) 670\n",
            "tensor(0.6459, device='cuda:0', grad_fn=<NllLossBackward>) 671\n",
            "tensor(0.5816, device='cuda:0', grad_fn=<NllLossBackward>) 672\n",
            "tensor(0.5391, device='cuda:0', grad_fn=<NllLossBackward>) 673\n",
            "tensor(0.5621, device='cuda:0', grad_fn=<NllLossBackward>) 674\n",
            "tensor(0.5994, device='cuda:0', grad_fn=<NllLossBackward>) 675\n",
            "tensor(0.5771, device='cuda:0', grad_fn=<NllLossBackward>) 676\n",
            "tensor(0.6233, device='cuda:0', grad_fn=<NllLossBackward>) 677\n",
            "tensor(0.5763, device='cuda:0', grad_fn=<NllLossBackward>) 678\n",
            "tensor(0.5450, device='cuda:0', grad_fn=<NllLossBackward>) 679\n",
            "tensor(0.5920, device='cuda:0', grad_fn=<NllLossBackward>) 680\n",
            "tensor(0.5527, device='cuda:0', grad_fn=<NllLossBackward>) 681\n",
            "tensor(0.5753, device='cuda:0', grad_fn=<NllLossBackward>) 682\n",
            "tensor(0.5997, device='cuda:0', grad_fn=<NllLossBackward>) 683\n",
            "tensor(0.5895, device='cuda:0', grad_fn=<NllLossBackward>) 684\n",
            "tensor(0.6167, device='cuda:0', grad_fn=<NllLossBackward>) 685\n",
            "tensor(0.6211, device='cuda:0', grad_fn=<NllLossBackward>) 686\n",
            "tensor(0.5691, device='cuda:0', grad_fn=<NllLossBackward>) 687\n",
            "tensor(0.5990, device='cuda:0', grad_fn=<NllLossBackward>) 688\n",
            "tensor(0.6297, device='cuda:0', grad_fn=<NllLossBackward>) 689\n",
            "tensor(0.6170, device='cuda:0', grad_fn=<NllLossBackward>) 690\n",
            "tensor(0.5766, device='cuda:0', grad_fn=<NllLossBackward>) 691\n",
            "tensor(0.6237, device='cuda:0', grad_fn=<NllLossBackward>) 692\n",
            "tensor(0.6063, device='cuda:0', grad_fn=<NllLossBackward>) 693\n",
            "tensor(0.5894, device='cuda:0', grad_fn=<NllLossBackward>) 694\n",
            "tensor(0.5918, device='cuda:0', grad_fn=<NllLossBackward>) 695\n",
            "tensor(0.5791, device='cuda:0', grad_fn=<NllLossBackward>) 696\n",
            "tensor(0.5851, device='cuda:0', grad_fn=<NllLossBackward>) 697\n",
            "tensor(0.5758, device='cuda:0', grad_fn=<NllLossBackward>) 698\n",
            "tensor(0.5904, device='cuda:0', grad_fn=<NllLossBackward>) 699\n",
            "tensor(0.6503, device='cuda:0', grad_fn=<NllLossBackward>) 700\n",
            "tensor(0.5833, device='cuda:0', grad_fn=<NllLossBackward>) 701\n",
            "tensor(0.5866, device='cuda:0', grad_fn=<NllLossBackward>) 702\n",
            "tensor(0.5739, device='cuda:0', grad_fn=<NllLossBackward>) 703\n",
            "tensor(0.5704, device='cuda:0', grad_fn=<NllLossBackward>) 704\n",
            "tensor(0.6050, device='cuda:0', grad_fn=<NllLossBackward>) 705\n",
            "tensor(0.5623, device='cuda:0', grad_fn=<NllLossBackward>) 706\n",
            "tensor(0.5846, device='cuda:0', grad_fn=<NllLossBackward>) 707\n",
            "tensor(0.5822, device='cuda:0', grad_fn=<NllLossBackward>) 708\n",
            "tensor(0.5932, device='cuda:0', grad_fn=<NllLossBackward>) 709\n",
            "tensor(0.5998, device='cuda:0', grad_fn=<NllLossBackward>) 710\n",
            "tensor(0.5672, device='cuda:0', grad_fn=<NllLossBackward>) 711\n",
            "tensor(0.5578, device='cuda:0', grad_fn=<NllLossBackward>) 712\n",
            "tensor(0.5602, device='cuda:0', grad_fn=<NllLossBackward>) 713\n",
            "tensor(0.6168, device='cuda:0', grad_fn=<NllLossBackward>) 714\n",
            "tensor(0.6127, device='cuda:0', grad_fn=<NllLossBackward>) 715\n",
            "tensor(0.5905, device='cuda:0', grad_fn=<NllLossBackward>) 716\n",
            "tensor(0.6276, device='cuda:0', grad_fn=<NllLossBackward>) 717\n",
            "tensor(0.5760, device='cuda:0', grad_fn=<NllLossBackward>) 718\n",
            "tensor(0.6278, device='cuda:0', grad_fn=<NllLossBackward>) 719\n",
            "tensor(0.6285, device='cuda:0', grad_fn=<NllLossBackward>) 720\n",
            "tensor(0.6410, device='cuda:0', grad_fn=<NllLossBackward>) 721\n",
            "tensor(0.5838, device='cuda:0', grad_fn=<NllLossBackward>) 722\n",
            "tensor(0.6139, device='cuda:0', grad_fn=<NllLossBackward>) 723\n",
            "tensor(0.6294, device='cuda:0', grad_fn=<NllLossBackward>) 724\n",
            "tensor(0.5316, device='cuda:0', grad_fn=<NllLossBackward>) 725\n",
            "tensor(0.6165, device='cuda:0', grad_fn=<NllLossBackward>) 726\n",
            "tensor(0.5820, device='cuda:0', grad_fn=<NllLossBackward>) 727\n",
            "tensor(0.5756, device='cuda:0', grad_fn=<NllLossBackward>) 728\n",
            "tensor(0.5322, device='cuda:0', grad_fn=<NllLossBackward>) 729\n",
            "tensor(0.5921, device='cuda:0', grad_fn=<NllLossBackward>) 730\n",
            "tensor(0.6146, device='cuda:0', grad_fn=<NllLossBackward>) 731\n",
            "tensor(0.6288, device='cuda:0', grad_fn=<NllLossBackward>) 732\n",
            "tensor(0.5561, device='cuda:0', grad_fn=<NllLossBackward>) 733\n",
            "tensor(0.6224, device='cuda:0', grad_fn=<NllLossBackward>) 734\n",
            "tensor(0.6279, device='cuda:0', grad_fn=<NllLossBackward>) 735\n",
            "tensor(0.6432, device='cuda:0', grad_fn=<NllLossBackward>) 736\n",
            "tensor(0.5989, device='cuda:0', grad_fn=<NllLossBackward>) 737\n",
            "tensor(0.5872, device='cuda:0', grad_fn=<NllLossBackward>) 738\n",
            "tensor(0.5893, device='cuda:0', grad_fn=<NllLossBackward>) 739\n",
            "tensor(0.6213, device='cuda:0', grad_fn=<NllLossBackward>) 740\n",
            "tensor(0.6177, device='cuda:0', grad_fn=<NllLossBackward>) 741\n",
            "tensor(0.6276, device='cuda:0', grad_fn=<NllLossBackward>) 742\n",
            "tensor(0.5844, device='cuda:0', grad_fn=<NllLossBackward>) 743\n",
            "tensor(0.5974, device='cuda:0', grad_fn=<NllLossBackward>) 744\n",
            "tensor(0.5957, device='cuda:0', grad_fn=<NllLossBackward>) 745\n",
            "tensor(0.6091, device='cuda:0', grad_fn=<NllLossBackward>) 746\n",
            "tensor(0.6121, device='cuda:0', grad_fn=<NllLossBackward>) 747\n",
            "tensor(0.5914, device='cuda:0', grad_fn=<NllLossBackward>) 748\n",
            "tensor(0.5393, device='cuda:0', grad_fn=<NllLossBackward>) 749\n",
            "tensor(0.6156, device='cuda:0', grad_fn=<NllLossBackward>) 750\n",
            "tensor(0.5984, device='cuda:0', grad_fn=<NllLossBackward>) 751\n",
            "tensor(0.5660, device='cuda:0', grad_fn=<NllLossBackward>) 752\n",
            "tensor(0.6654, device='cuda:0', grad_fn=<NllLossBackward>) 753\n",
            "tensor(0.5877, device='cuda:0', grad_fn=<NllLossBackward>) 754\n",
            "tensor(0.5731, device='cuda:0', grad_fn=<NllLossBackward>) 755\n",
            "tensor(0.5659, device='cuda:0', grad_fn=<NllLossBackward>) 756\n",
            "tensor(0.5634, device='cuda:0', grad_fn=<NllLossBackward>) 757\n",
            "tensor(0.5884, device='cuda:0', grad_fn=<NllLossBackward>) 758\n",
            "tensor(0.5696, device='cuda:0', grad_fn=<NllLossBackward>) 759\n",
            "tensor(0.6131, device='cuda:0', grad_fn=<NllLossBackward>) 760\n",
            "tensor(0.5955, device='cuda:0', grad_fn=<NllLossBackward>) 761\n",
            "tensor(0.5409, device='cuda:0', grad_fn=<NllLossBackward>) 762\n",
            "tensor(0.5618, device='cuda:0', grad_fn=<NllLossBackward>) 763\n",
            "tensor(0.5549, device='cuda:0', grad_fn=<NllLossBackward>) 764\n",
            "tensor(0.6510, device='cuda:0', grad_fn=<NllLossBackward>) 765\n",
            "tensor(0.6496, device='cuda:0', grad_fn=<NllLossBackward>) 766\n",
            "tensor(0.6071, device='cuda:0', grad_fn=<NllLossBackward>) 767\n",
            "tensor(0.5732, device='cuda:0', grad_fn=<NllLossBackward>) 768\n",
            "tensor(0.5917, device='cuda:0', grad_fn=<NllLossBackward>) 769\n",
            "tensor(0.5500, device='cuda:0', grad_fn=<NllLossBackward>) 770\n",
            "tensor(0.6094, device='cuda:0', grad_fn=<NllLossBackward>) 771\n",
            "tensor(0.5558, device='cuda:0', grad_fn=<NllLossBackward>) 772\n",
            "Average train loss: 0.6092203807707437\n",
            "eval loss  :0.5898712873458862\n",
            "eval loss  :1.2423353791236877\n",
            "eval loss  :1.8550036549568176\n",
            "eval loss  :2.413446605205536\n",
            "eval loss  :3.007683753967285\n",
            "eval loss  :3.57972514629364\n",
            "eval loss  :4.176553308963776\n",
            "eval loss  :4.784096539020538\n",
            "eval loss  :5.341433942317963\n",
            "eval loss  :5.974142551422119\n",
            "eval loss  :6.5368891954422\n",
            "eval loss  :7.125337183475494\n",
            "eval loss  :7.738259136676788\n",
            "eval loss  :8.354388415813446\n",
            "eval loss  :8.916514039039612\n",
            "eval loss  :9.483238637447357\n",
            "eval loss  :10.044818878173828\n",
            "eval loss  :10.616012752056122\n",
            "eval loss  :11.187949776649475\n",
            "eval loss  :11.735122799873352\n",
            "eval loss  :12.287451386451721\n",
            "eval loss  :12.918613135814667\n",
            "eval loss  :13.496304869651794\n",
            "eval loss  :14.08663123846054\n",
            "eval loss  :14.719198226928711\n",
            "eval loss  :15.253054738044739\n",
            "eval loss  :15.817331969738007\n",
            "eval loss  :16.4084113240242\n",
            "eval loss  :17.047690629959106\n",
            "eval loss  :17.621039867401123\n",
            "eval loss  :18.229863703250885\n",
            "eval loss  :18.811921536922455\n",
            "eval loss  :19.358466744422913\n",
            "eval loss  :19.880724370479584\n",
            "eval loss  :20.505516231060028\n",
            "eval loss  :21.11049598455429\n",
            "eval loss  :21.66484659910202\n",
            "eval loss  :22.297908306121826\n",
            "eval loss  :22.938248693943024\n",
            "eval loss  :23.45804452896118\n",
            "eval loss  :24.01830303668976\n",
            "eval loss  :24.621438205242157\n",
            "eval loss  :25.275935351848602\n",
            "eval loss  :25.792280316352844\n",
            "eval loss  :26.363089501857758\n",
            "eval loss  :26.96388816833496\n",
            "eval loss  :27.642252564430237\n",
            "eval loss  :28.207814395427704\n",
            "eval loss  :28.80599218606949\n",
            "eval loss  :29.367023766040802\n",
            "eval loss  :29.937692046165466\n",
            "eval loss  :30.463883936405182\n",
            "eval loss  :31.031190514564514\n",
            "eval loss  :31.651170551776886\n",
            "eval loss  :32.269441068172455\n",
            "eval loss  :32.85559785366058\n",
            "eval loss  :33.45282942056656\n",
            "eval loss  :33.98612678050995\n",
            "eval loss  :34.583675026893616\n",
            "eval loss  :35.202360928058624\n",
            "eval loss  :35.76882392168045\n",
            "eval loss  :36.3272904753685\n",
            "eval loss  :36.948563396930695\n",
            "eval loss  :37.52600806951523\n",
            "eval loss  :38.037128925323486\n",
            "eval loss  :38.62316745519638\n",
            "eval loss  :39.16555619239807\n",
            "eval loss  :39.7629771232605\n",
            "eval loss  :40.35044866800308\n",
            "eval loss  :40.864206194877625\n",
            "eval loss  :41.44021129608154\n",
            "eval loss  :41.99031609296799\n",
            "eval loss  :42.5924271941185\n",
            "eval loss  :43.16345226764679\n",
            "eval loss  :43.74008023738861\n",
            "eval loss  :44.33381628990173\n",
            "eval loss  :44.970145881175995\n",
            "eval loss  :45.524012982845306\n",
            "eval loss  :46.05138558149338\n",
            "eval loss  :46.61958074569702\n",
            "eval loss  :47.22409117221832\n",
            "eval loss  :47.831116020679474\n",
            "eval loss  :48.517815589904785\n",
            "eval loss  :49.032169342041016\n",
            "eval loss  :49.596021592617035\n",
            "eval loss  :50.230772614479065\n",
            "\n",
            "CPU times: user 10min 11s, sys: 6min 27s, total: 16min 39s\n",
            "Wall time: 16min 40s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgJW1V-Br2nl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "55c20d75-f021-4fe2-b955-82f4c768f53d"
      },
      "source": [
        "print(avg_train_loss)\n",
        "print(eval_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6092203807707437\n",
            "0.584078751331152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk8NOFeSr2rX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b757a352-dbd8-4d26-ba60-362caf7c1552"
      },
      "source": [
        "acc=[]\n",
        "for j in range(len(valid_dataloader)):\n",
        " acc.append(sum([1 for i in range(0,128) if predictions[j][i]==true_labels[j][i]])/128)\n",
        "sum(acc)/len(valid_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42014898255813954"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQCiEr86RLAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_tweet(original_tweet,idx_start,idx_end,offsets):\n",
        "    filtered_output  = \"\"\n",
        "    for ix in range(idx_start, idx_end + 1):\n",
        "        filtered_output += original_tweet[offsets[ix][0]: offsets[ix][1]]\n",
        "        if (ix+1) < len(offsets) and offsets[ix][1] < offsets[ix+1][0]:\n",
        "            filtered_output += \" \"\n",
        "    return filtered_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26utpVNkWuuI",
        "colab_type": "text"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A07tNmtBNI2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHr0uPfXSNDQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d714771c-6015-4459-f185-cf4acec11869"
      },
      "source": [
        "id1='1hlqiVCKMApFC5WEexahUouBqFh5mi7b0'\n",
        "print(id1)\n",
        "downloaded = drive.CreateFile({'id':id1}) \n",
        "downloaded.GetContentFile('test.csv')  \n",
        "test = pd.read_csv('test.csv')\n",
        "test=test.drop([i for i in range(len(test['text'])) if  test['text'][i] in ['nan', np.nan]])\n",
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1hlqiVCKMApFC5WEexahUouBqFh5mi7b0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3534, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwu16vn7cZ4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subm_list=[]\n",
        "for test_ids in test['textID']:\n",
        "  if test['sentiment'][test['textID']==test_ids].values[0]=='neutral':\n",
        "    selected_text=test['text'][test['textID']==test_ids].values[0]\n",
        "  else:\n",
        "    test_token=tokenizer_brt.encode_plus(test['text'][test['textID']==test_ids].values[0],max_length=128,pad_to_max_length=True)\n",
        "    test_input_ids = torch.tensor([test_token['input_ids']]).cuda()\n",
        "    with torch.no_grad():\n",
        "      output = model(test_input_ids)\n",
        "    label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
        "    indexes=[i for i in range(len(label_indices[0])) if label_indices[0][i]==1]\n",
        "    encoded_text=tokenizer.encode(test['text'][test['textID']==test_ids].values[0])\n",
        "    if len(indexes)>0:\n",
        "      start = indexes[0]\n",
        "      end =  indexes[-1]\n",
        "    else:  \n",
        "      start = 0\n",
        "      end = len(encoded_text.ids) - 1\n",
        "    if end >= len(encoded_text.ids): \n",
        "      end = len(encoded_text.ids) - 1\n",
        "    #print(test_ids,start,end,len(encoded_test_token.offsets))\n",
        "    selected_text=decode_tweet(test['text'][test['textID']==test_ids].values[0],start,end,encoded_text.offsets)\n",
        "  subm_list.append({'textID':test_ids,'text':test['text'][test['textID']==test_ids].values[0],\\\n",
        "                     'sentiment':test['sentiment'][test['textID']==test_ids].values[0],'selected_text':selected_text})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFrqhI7wD3AR",
        "colab_type": "text"
      },
      "source": [
        "Ready for Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKTOP6M77OZC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "49220243-c7fd-4b83-ddfe-7319eb20e988"
      },
      "source": [
        "pd.DataFrame(subm_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>selected_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>f87dea47db</td>\n",
              "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>96d74cb729</td>\n",
              "      <td>Shanghai is also really exciting (precisely -...</td>\n",
              "      <td>positive</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eee518ae67</td>\n",
              "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
              "      <td>negative</td>\n",
              "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01082688c6</td>\n",
              "      <td>happy bday!</td>\n",
              "      <td>positive</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33987a8ee5</td>\n",
              "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
              "      <td>positive</td>\n",
              "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3529</th>\n",
              "      <td>e5f0e6ef4b</td>\n",
              "      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>its at 3 am, im very tired but i can`t sleep b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3530</th>\n",
              "      <td>416863ce47</td>\n",
              "      <td>All alone in this old house again.  Thanks for...</td>\n",
              "      <td>positive</td>\n",
              "      <td>Thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3531</th>\n",
              "      <td>6332da480c</td>\n",
              "      <td>I know what you mean. My little dog is sinkin...</td>\n",
              "      <td>negative</td>\n",
              "      <td>I know what you mean. My little dog is sinkin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3532</th>\n",
              "      <td>df1baec676</td>\n",
              "      <td>_sutra what is your next youtube video gonna b...</td>\n",
              "      <td>positive</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3533</th>\n",
              "      <td>469e15c5a8</td>\n",
              "      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n",
              "      <td>positive</td>\n",
              "      <td>http://twitpic.com/4woj2 - omgssh ang cute ng...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3534 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          textID  ...                                      selected_text\n",
              "0     f87dea47db  ...  Last session of the day  http://twitpic.com/67ezh\n",
              "1     96d74cb729  ...                                              Good \n",
              "2     eee518ae67  ...  Recession hit Veronique Branquinho, she has to...\n",
              "3     01082688c6  ...                                             happy \n",
              "4     33987a8ee5  ...             http://twitpic.com/4w75p - I like it!!\n",
              "...          ...  ...                                                ...\n",
              "3529  e5f0e6ef4b  ...  its at 3 am, im very tired but i can`t sleep b...\n",
              "3530  416863ce47  ...                                            Thanks \n",
              "3531  6332da480c  ...   I know what you mean. My little dog is sinkin...\n",
              "3532  df1baec676  ...                                              love \n",
              "3533  469e15c5a8  ...   http://twitpic.com/4woj2 - omgssh ang cute ng...\n",
              "\n",
              "[3534 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvP8VNqdD19F",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r7Me04dXh_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxtuYA8HXiCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpLeCzDrXiF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4gNgeEwXiJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}